ğŸ“ CampusGPT â€“ AI-Powered College Information Assistant
RAG + LangChain + FAISS + Groq LLM + FastAPI + Streamlit

CampusGPT is an AI-powered assistant designed to help students, faculty, and visitors quickly access verified college information such as:

Faculty list

Admission criteria

Fee structure

Course details

Department info

Campus facilities

Important notices

Academic calendar

And moreâ€¦

CampusGPT uses RAG (Retrieval Augmented Generation) with FAISS vector search + LLM reasoning to provide accurate answers based on real college documents.

ğŸš€ Features
âœ”ï¸ RAG-powered Q&A

Uses vector search (FAISS) + Groq LLM to answer questions only from your college documents.

âœ”ï¸ Secure Document Ingestion

Upload PDFs or ingest an entire directory of documents.

âœ”ï¸ Smart Retrieval

Automatically retrieves ALL faculty details, department data, or full pages based on the query.

âœ”ï¸ Clean Streamlit UI

User-friendly web interface for students.

âœ”ï¸ FastAPI Backend

Production-ready backend with CORS, router structure, environment variables.

âœ”ï¸ Works Offline after Document Ingestion

Once the FAISS database is created, no internet is needed for vector search.

ğŸ“ Project Structure
CampusGPT/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                     # FastAPI entry point
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ gpt.py                  # API endpoints
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag_langchain.py        # RAG Logic (FAISS + LLM)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â”‚   â””â”€â”€ db_faiss/               # Generated FAISS index
â”‚   â”œâ”€â”€ data/                        # PDF files for ingestion
â”‚   â””â”€â”€ .env                        # environment variables
â”‚
â”œâ”€â”€ streamlit_app.py                # Frontend UI
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Create Virtual Environment
python -m venv campus
campus\Scripts\activate   # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Add your .env inside /backend/
GROQ_API_KEY=your_key_here
GROQ_MODEL_NAME=llama-3.1-8b-instant
DB_FAISS_PATH=backend/vectorstore/db_faiss
UPLOAD_DIR=uploads
ADMIN_TOKEN=hackathon_admin
GROQ_MAX_TOKENS=1500
DEFAULT_K=8

ğŸ“š Document Ingestion (Very Important)
Step 1 â€” Place your PDFs inside:
backend/data/


Example:

backend/data/Faculty.pdf
backend/data/Admission.pdf
backend/data/Syllabus.pdf

Step 2 â€” Start the backend:
uvicorn backend.main:app --port 8000

Step 3 â€” Open Swagger docs:

ğŸ‘‰ http://127.0.0.1:8000/docs

Step 4 â€” Ingest all PDFs:

Use endpoint:

POST /gpt/ingest_dir


Body:

admin_token = hackathon_admin


If successful:

{
  "status": "ok",
  "ingested_chunks": 345
}


FAISS index appears at:

backend/vectorstore/db_faiss/index.faiss
backend/vectorstore/db_faiss/index.pkl

ğŸš€ Run CampusGPT Frontend

Open a new terminal:

campus\Scripts\activate
streamlit run streamlit_app.py


Now open:

ğŸ‘‰ http://localhost:8501

ğŸ§  How CampusGPT Works

PDFs â†’ chunked â†’ embedded using HuggingFace (MiniLM-L6-v2)

Stored in a FAISS vector database

Query â†’ converted to embedding

Top k matching chunks retrieved
(Smart mode for faculty queries â†’ retrieves ALL relevant chunks)

Prompt created using retrieved context

Groq LLM (llama-3.1-8b-instant) generates reliable answer

ğŸ’¡ Example Queries

â€œGive all faculty names of Computer Engineering Departmentâ€

â€œWhat is the eligibility for B.Tech admission?â€

â€œGive me complete fee structure for all coursesâ€

â€œList all labs in Mechanical Engineeringâ€

â€œWhat documents are required for admission?â€